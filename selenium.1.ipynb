{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c242d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.9/site-packages (4.7.2)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea130b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d287742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/vh3pm6nx355b0g53flh1j6n80000gn/T/ipykernel_11266/3905516229.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"https://chromedriver.storage.googleapis.com/108.0.5359.71/chromedriver_mac64.unzip\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"https://chromedriver.storage.googleapis.com/108.0.5359.71/chromedriver_mac64.unzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 1\n",
    "#Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,(\"suggestor-input \"))\n",
    "designation.send_keys('Data analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e37d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff315ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tag= driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    j=i.text\n",
    "    job_location.append(j)\n",
    "company_tag= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    j=i.text\n",
    "    company_name.append(j)\n",
    "    \n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')   \n",
    "for i in exp_tag[0:10]:\n",
    "    j=i.text\n",
    "    experience_required.append(j)\n",
    "    \n",
    "    \n",
    "\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"JOB TITLE\":job_title,\n",
    "                 \"JOB LOCATION\":job_location,\n",
    "                 \"COMPANY\":company_name,\n",
    "                 \"EXPERIENCE\":experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION NO 2\n",
    "#  Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e693d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,(\"suggestor-input \"))\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd6504-717d-427c-a82a-d9370036be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f06525",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tag= driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    j=i.text\n",
    "    job_location.append(j)\n",
    "company_tag= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    j=i.text\n",
    "    company_name.append(j)\n",
    "    \n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')   \n",
    "for i in exp_tag[0:10]:\n",
    "    j=i.text\n",
    "    experience_required.append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"JOB TITLE\":job_title,\n",
    "                 \"JOB LOCATION\":job_location,\n",
    "                 \"COMPANY\":company_name,\n",
    "                 })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question--3\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('DELHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd97083",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ad6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_filter = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft filterLabel\"]')\n",
    "\n",
    "        \n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tag= driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    j=i.text\n",
    "    job_location.append(j)\n",
    "company_tag= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    j=i.text\n",
    "    company_name.append(j)\n",
    "    \n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')   \n",
    "for i in exp_tag[0:10]:\n",
    "    j=i.text\n",
    "    experience_required.append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"JOB TITLE\":job_title,\n",
    "                 \"JOB LOCATION\":job_location,\n",
    "                 \"COMPANY\":company_name,\n",
    "                 })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0776e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: 1. Brand\n",
    "#2. Product Description\n",
    "#3. Price\n",
    "#The attributes which you have to scrape is ticked marked in the below image.\n",
    "#To scrape the data you have to go through following steps:\n",
    "#1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "#2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "#click the search icon\n",
    "#3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "#required data a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2f4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93cf62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "location.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c263775",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5c0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eeb9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "items=[]\n",
    "start=0\n",
    "end=2\n",
    "for i in range(start,end):\n",
    "    title=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for j in title:\n",
    "        brand.append(j.text)\n",
    "                              \n",
    "    title_1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    try:\n",
    "        for k in title_1:\n",
    "            product_description.append(k.text)\n",
    "    except:  \n",
    "            product_description.append(\"--\")\n",
    "                              \n",
    "    title_2=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for l in title_2:\n",
    "         price.append(l.text)\n",
    "                              \n",
    "next_element=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_element.click()\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6400d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 78 80\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774f958-fc2e-431a-ad6a-e0bd94626a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"brand\":brand,\n",
    "                 \"product\":product_description,\n",
    "                 \"price\":price,\n",
    "                 })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3526682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69afd7-140f-450d-b749-4489e4e2b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab779f4-de3a-4a23-a0a0-1826afd4e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "location.send_keys('SNEAKERS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8655b72-7fe0-441a-b264-650ac167921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98166f44-712f-4f0b-adf3-7c8b13bced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105d0a79-4b2a-402a-a880-35fe36d70f44",
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=109.0.5414.119)\nStacktrace:\n0   chromedriver                        0x0000000103714fa8 chromedriver + 4886440\n1   chromedriver                        0x0000000103692643 chromedriver + 4351555\n2   chromedriver                        0x00000001032e0b27 chromedriver + 477991\n3   chromedriver                        0x00000001032e4f78 chromedriver + 495480\n4   chromedriver                        0x00000001032e4c46 chromedriver + 494662\n5   chromedriver                        0x00000001032e504c chromedriver + 495692\n6   chromedriver                        0x000000010331df35 chromedriver + 728885\n7   chromedriver                        0x000000010334b5d2 chromedriver + 914898\n8   chromedriver                        0x00000001033173dd chromedriver + 701405\n9   chromedriver                        0x000000010334b78e chromedriver + 915342\n10  chromedriver                        0x00000001033665fe chromedriver + 1025534\n11  chromedriver                        0x000000010334b3a3 chromedriver + 914339\n12  chromedriver                        0x000000010331557f chromedriver + 693631\n13  chromedriver                        0x0000000103316b1e chromedriver + 699166\n14  chromedriver                        0x00000001036e1b9e chromedriver + 4676510\n15  chromedriver                        0x00000001036e691e chromedriver + 4696350\n16  chromedriver                        0x00000001036ee19f chromedriver + 4727199\n17  chromedriver                        0x00000001036e781a chromedriver + 4700186\n18  chromedriver                        0x00000001036baa62 chromedriver + 4516450\n19  chromedriver                        0x00000001037068c8 chromedriver + 4827336\n20  chromedriver                        0x0000000103706a45 chromedriver + 4827717\n21  chromedriver                        0x000000010371c7ef chromedriver + 4917231\n22  libsystem_pthread.dylib             0x00007ff80d23e4e1 _pthread_start + 125\n23  libsystem_pthread.dylib             0x00007ff80d239f6b thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m title\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_2WkVRV\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m title:\n\u001b[0;32m----> 6\u001b[0m     brand\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n\u001b[1;32m      7\u001b[0m title_1\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//a[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIRpwTa\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m title_1:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webelement.py:89\u001b[0m, in \u001b[0;36mWebElement.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124;03m\"\"\"The text of the element.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webelement.py:410\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    408\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    409\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=109.0.5414.119)\nStacktrace:\n0   chromedriver                        0x0000000103714fa8 chromedriver + 4886440\n1   chromedriver                        0x0000000103692643 chromedriver + 4351555\n2   chromedriver                        0x00000001032e0b27 chromedriver + 477991\n3   chromedriver                        0x00000001032e4f78 chromedriver + 495480\n4   chromedriver                        0x00000001032e4c46 chromedriver + 494662\n5   chromedriver                        0x00000001032e504c chromedriver + 495692\n6   chromedriver                        0x000000010331df35 chromedriver + 728885\n7   chromedriver                        0x000000010334b5d2 chromedriver + 914898\n8   chromedriver                        0x00000001033173dd chromedriver + 701405\n9   chromedriver                        0x000000010334b78e chromedriver + 915342\n10  chromedriver                        0x00000001033665fe chromedriver + 1025534\n11  chromedriver                        0x000000010334b3a3 chromedriver + 914339\n12  chromedriver                        0x000000010331557f chromedriver + 693631\n13  chromedriver                        0x0000000103316b1e chromedriver + 699166\n14  chromedriver                        0x00000001036e1b9e chromedriver + 4676510\n15  chromedriver                        0x00000001036e691e chromedriver + 4696350\n16  chromedriver                        0x00000001036ee19f chromedriver + 4727199\n17  chromedriver                        0x00000001036e781a chromedriver + 4700186\n18  chromedriver                        0x00000001036baa62 chromedriver + 4516450\n19  chromedriver                        0x00000001037068c8 chromedriver + 4827336\n20  chromedriver                        0x0000000103706a45 chromedriver + 4827717\n21  chromedriver                        0x000000010371c7ef chromedriver + 4917231\n22  libsystem_pthread.dylib             0x00007ff80d23e4e1 _pthread_start + 125\n23  libsystem_pthread.dylib             0x00007ff80d239f6b thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=3\n",
    "for i in range(start,end):\n",
    "    title=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for col in title:\n",
    "        brand.append(col.text)\n",
    "    title_1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for k in title_1:\n",
    "        product_description.append(k.text)\n",
    "        time.sleep(2)\n",
    "    title_2=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for l in title_2:\n",
    "         price.append(l.text)\n",
    "    next_element=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_element.click()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e5f2a-3687-4d77-a408-a9e0577de695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4718dd7-a611-4ef3-9e74-5ea8d76b8741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
